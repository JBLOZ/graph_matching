{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9eaac4-2e4a-4a67-8e84-4b11a928bd81",
   "metadata": {},
   "source": [
    "# Aceleración de Matching y Procesamiento de Grafos\n",
    "\n",
    "Este notebook integra mejoras de paralelización, vectorización y uso opcional de CUDA (con CuPy) para acelerar la ejecución del código original sin alterar su lógica fundamental. Las mejoras se aplican a:\n",
    "\n",
    "- **Vectorización**: Se elimina el bucle anidado en el cálculo de la matriz de coste en `enhanced_spatial_matching`.\n",
    "- **Paralelización**: Se paralelizan los cálculos de hitting times y el procesamiento de pares en la evaluación de precisión.\n",
    "- **Uso de CUDA (opcional)**: Se incluye una versión acelerada con CuPy para operaciones matriciales intensivas.\n",
    "\n",
    "Asegúrate de tener instaladas las librerías necesarias (por ejemplo, `cupy`, `networkx`, `node2vec`, etc.) y de disponer de una GPU para aprovechar la aceleración por CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c745ecf4-d2c2-48fa-8eaf-2936a2b53b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-24 09:33:07] INFO: Logging level: INFO\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Agregar la ruta al DataLoader\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.dataloader import DataLoader\n",
    "\n",
    "# Configuración del logger\n",
    "logging.getLogger(\"gensim\").setLevel(logging.WARNING)\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(f'Logging level: {logging.getLevelName(logger.getEffectiveLevel())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ef3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jordi\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Intentar importar CuPy para la versión CUDA (si está disponible)\n",
    "print(sys.executable)\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = True\n",
    "except ImportError:\n",
    "    !{} -m pip install cupy\n",
    "    import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a4d30f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a59784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Agregar la ruta al DataLoader\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from data.dataloader import DataLoader\n",
    "\n",
    "# Configuración del logger\n",
    "logging.getLogger(\"gensim\").setLevel(logging.WARNING)\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(f'Logging level: {logging.getLevelName(logger.getEffectiveLevel())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93641a74-69f3-4b9e-98a5-950d75f6e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-24 00:20:25] INFO: Dataset cargado correctamente\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset usando DataLoader\n",
    "dl = DataLoader()\n",
    "dlf = dl.load_data()\n",
    "logger.info('Dataset cargado correctamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ea58bc-4d26-4d1c-bac4-4f8a55877d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_and_preprocess_images(row1, row2, target_size=(512,512)):\n",
    "    \"\"\"\n",
    "    Carga y redimensiona dos imágenes y ajusta los keypoints a un tamaño objetivo.\n",
    "    \"\"\"\n",
    "    img_path1 = row1['img']\n",
    "    img_path2 = row2['img']\n",
    "    mat_path1 = row1['mat']\n",
    "    mat_path2 = row2['mat']\n",
    "\n",
    "    img1 = Image.open(img_path1)\n",
    "    img2 = Image.open(img_path2)\n",
    "    \n",
    "    mat_data1 = sio.loadmat(mat_path1)\n",
    "    mat_data2 = sio.loadmat(mat_path2)\n",
    "    kpts1 = np.array(mat_data1['pts_coord'])\n",
    "    kpts2 = np.array(mat_data2['pts_coord'])\n",
    "    \n",
    "    # Ajustar los keypoints al nuevo tamaño\n",
    "    orig_size1 = img1.size\n",
    "    orig_size2 = img2.size\n",
    "    kpts1[0] = kpts1[0] * target_size[0] / orig_size1[0]\n",
    "    kpts1[1] = kpts1[1] * target_size[1] / orig_size1[1]\n",
    "    kpts2[0] = kpts2[0] * target_size[0] / orig_size2[0]\n",
    "    kpts2[1] = kpts2[1] * target_size[1] / orig_size2[1]\n",
    "    \n",
    "    img1 = img1.resize(target_size, resample=Image.BILINEAR)\n",
    "    img2 = img2.resize(target_size, resample=Image.BILINEAR)\n",
    "    \n",
    "    return img1, img2, kpts1, kpts2\n",
    "\n",
    "def load_keypoints_from_row(row1, row2):\n",
    "    mat_path1 = row1['mat']\n",
    "    mat_path2 = row2['mat']\n",
    "\n",
    "    kpts1 = np.array(sio.loadmat(mat_path1)['pts_coord'])   \n",
    "    kpts2 = np.array(sio.loadmat(mat_path2)['pts_coord'])\n",
    "\n",
    "    return kpts1, kpts2\n",
    "\n",
    "def visualize_combined(img1, img2, kpts1, kpts2, adj_matrix1, adj_matrix2, matching):\n",
    "    \"\"\"\n",
    "    Visualiza dos imágenes lado a lado con grafos de Delaunay y líneas que indican el matching.\n",
    "    \"\"\"\n",
    "    h1, w1 = np.array(img1).shape[:2]\n",
    "    h2, w2 = np.array(img2).shape[:2]\n",
    "\n",
    "    composite_img = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8)\n",
    "    composite_img[:h1, :w1, :] = img1\n",
    "    composite_img[:h2, w1:w1+w2, :] = img2\n",
    "\n",
    "    # Desplazar keypoints de la segunda imagen\n",
    "    kpts2_shifted = kpts2.copy()\n",
    "    kpts2_shifted[0, :] += w1\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(composite_img)\n",
    "\n",
    "    color = mcolors.CSS4_COLORS['yellow']\n",
    "\n",
    "    # Dibujar grafos de Delaunay\n",
    "    for kpts, adj_matrix in zip([kpts1, kpts2_shifted], [adj_matrix1, adj_matrix2]):\n",
    "        N = kpts.shape[1]\n",
    "        for i in range(N):\n",
    "            for j in range(i+1, N):\n",
    "                if adj_matrix[i, j]:\n",
    "                    plt.plot([kpts[0, i], kpts[0, j]], [kpts[1, i], kpts[1, j]], '-', color=color, linewidth=1)\n",
    "        plt.scatter(kpts[0], kpts[1], c=color, edgecolors='w', s=80)\n",
    "\n",
    "    # Dibujar matching\n",
    "    row_ind, col_ind = np.where(matching == 1)\n",
    "    for r, c in zip(row_ind, col_ind):\n",
    "        x1, y1 = kpts1[:, r]\n",
    "        x2, y2 = kpts2_shifted[:, c]\n",
    "        if r == c:\n",
    "            plt.plot([x1, x2], [y1, y2], '-', color=mcolors.CSS4_COLORS['lime'], linewidth=1)\n",
    "        else:\n",
    "            plt.plot([x1, x2], [y1, y2], '-', color='r', linewidth=1)\n",
    "\n",
    "    plt.title(\"Matching y Triangulación Delaunay\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def delaunay_triangulation(kpts):\n",
    "    \"\"\"\n",
    "    Construye la matriz de adyacencia usando Delaunay sobre los keypoints.\n",
    "    \"\"\"\n",
    "    pts = kpts.T\n",
    "    tri = Delaunay(pts)\n",
    "    N = pts.shape[0]\n",
    "    A = np.zeros((N, N))\n",
    "    for simplex in tri.simplices:\n",
    "        for i in range(len(simplex)):\n",
    "            for j in range(i+1, len(simplex)):\n",
    "                A[simplex[i], simplex[j]] = 1\n",
    "                A[simplex[j], simplex[i]] = 1\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33d7d0b-41b0-4f67-80f5-1f965b0fcbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node2vec_embeddings(G, dimensions=64, num_walks=10, walk_length=30):\n",
    "    \"\"\"\n",
    "    Calcula embeddings usando node2vec sobre el grafo G.\n",
    "    \"\"\"\n",
    "    node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=16, quiet=True)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    n = G.number_of_nodes()\n",
    "    embeddings = np.zeros((n, dimensions))\n",
    "    for node in G.nodes():\n",
    "        embeddings[node] = model.wv[str(node)]\n",
    "    return embeddings\n",
    "\n",
    "def hitting_time(G, start_node, destination_node, num_walks=100):\n",
    "    \"\"\"\n",
    "    Aproxima el hitting time entre dos nodos mediante caminatas aleatorias.\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "    for _ in range(num_walks):\n",
    "        current = start_node\n",
    "        steps = 0\n",
    "        while current != destination_node and steps < 1000:\n",
    "            neighbors = list(G.neighbors(current))\n",
    "            if not neighbors:\n",
    "                break\n",
    "            current = random.choice(neighbors)\n",
    "            steps += 1\n",
    "        hits.append(steps)\n",
    "    return np.mean(hits)\n",
    "\n",
    "def compute_hitting_time_matrix_parallel(G):\n",
    "    \"\"\"\n",
    "    Computa la matriz de hitting times de forma paralela usando ProcessPoolExecutor.\n",
    "    \"\"\"\n",
    "    n = G.number_of_nodes()\n",
    "    hitting_times = np.zeros((n, n))\n",
    "\n",
    "    def compute_pair(i, j):\n",
    "        h_time = hitting_time(G, i, j)\n",
    "        return (i, j, h_time)\n",
    "\n",
    "    pairs = [(i, j) for i in range(n) for j in range(i+1, n)]\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = {executor.submit(compute_pair, i, j): (i, j) for i, j in pairs}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            i, j, h_time = future.result()\n",
    "            hitting_times[i, j] = h_time\n",
    "            hitting_times[j, i] = h_time\n",
    "    return hitting_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8827b2a-6b53-4af9-9c95-685b0247e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_spatial_matching(kpts1, kpts2, adj_matrix1, adj_matrix2):\n",
    "    \"\"\"\n",
    "    Realiza matching utilizando características espaciales, embeddings (node2vec) y perfiles de hitting times.\n",
    "    Esta versión vectoriza el cálculo de la matriz de coste.\n",
    "    \"\"\"\n",
    "    n1 = kpts1.shape[1]\n",
    "    n2 = kpts2.shape[1]\n",
    "    \n",
    "    # Construir grafos\n",
    "    G1 = nx.from_numpy_array(adj_matrix1)\n",
    "    G2 = nx.from_numpy_array(adj_matrix2)\n",
    "    \n",
    "    node2vec_emb1 = compute_node2vec_embeddings(G1)\n",
    "    node2vec_emb2 = compute_node2vec_embeddings(G2)\n",
    "    \n",
    "    # Usar la versión paralela para hitting times (CPU)\n",
    "    hitting_times1 = compute_hitting_time_matrix_parallel(G1)\n",
    "    hitting_times2 = compute_hitting_time_matrix_parallel(G2)\n",
    "    \n",
    "    profile1 = np.mean(hitting_times1, axis=1)  # (n1,)\n",
    "    profile2 = np.mean(hitting_times2, axis=1)  # (n2,)\n",
    "    \n",
    "    # Calcular distancias espaciales de forma vectorizada\n",
    "    spatial_dist_matrix = np.linalg.norm(kpts1.T[:, np.newaxis, :] - kpts2.T[np.newaxis, :, :], axis=2)\n",
    "    \n",
    "    # Calcular distancias entre embeddings\n",
    "    node2vec_dist_matrix = np.linalg.norm(node2vec_emb1[:, np.newaxis, :] - node2vec_emb2[np.newaxis, :, :], axis=2)\n",
    "    \n",
    "    # Diferencia en perfiles de hitting times\n",
    "    hitting_profile_matrix = np.abs(profile1[:, np.newaxis] - profile2[np.newaxis, :])\n",
    "    \n",
    "    cost_matrix = 0.4 * spatial_dist_matrix + 0.3 * node2vec_dist_matrix + 0.3 * hitting_profile_matrix\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    matching = np.zeros((n1, n2), dtype=int)\n",
    "    matching[row_ind, col_ind] = 1\n",
    "    return matching\n",
    "\n",
    "# Versión acelerada con CUDA usando CuPy (si está disponible)\n",
    "def enhanced_spatial_matching_cuda(kpts1, kpts2, adj_matrix1, adj_matrix2):\n",
    "    \"\"\"\n",
    "    Versión de enhanced_spatial_matching que utiliza CuPy para acelerar operaciones matriciales en GPU.\n",
    "    \"\"\"\n",
    "    if not HAS_CUPY:\n",
    "        raise ImportError(\"CuPy no está instalado o no se encontró una GPU disponible.\")\n",
    "        \n",
    "    n1 = kpts1.shape[1]\n",
    "    n2 = kpts2.shape[1]\n",
    "    \n",
    "    G1 = nx.from_numpy_array(adj_matrix1)\n",
    "    G2 = nx.from_numpy_array(adj_matrix2)\n",
    "    \n",
    "    node2vec_emb1 = compute_node2vec_embeddings(G1)\n",
    "    node2vec_emb2 = compute_node2vec_embeddings(G2)\n",
    "    \n",
    "    # Para hitting times se utiliza la versión CPU\n",
    "    hitting_times1 = compute_hitting_time_matrix_parallel(G1)\n",
    "    hitting_times2 = compute_hitting_time_matrix_parallel(G2)\n",
    "    \n",
    "    profile1 = np.mean(hitting_times1, axis=1)\n",
    "    profile2 = np.mean(hitting_times2, axis=1)\n",
    "    \n",
    "    # Convertir a arrays de CuPy\n",
    "    kpts1_cp = cp.asarray(kpts1.T)  # Shape: (n1, 2)\n",
    "    kpts2_cp = cp.asarray(kpts2.T)  \n",
    "    emb1_cp = cp.asarray(node2vec_emb1)\n",
    "    emb2_cp = cp.asarray(node2vec_emb2)\n",
    "    profile1_cp = cp.asarray(profile1)\n",
    "    profile2_cp = cp.asarray(profile2)\n",
    "    \n",
    "    spatial_dist_matrix = cp.linalg.norm(kpts1_cp[:, cp.newaxis, :] - kpts2_cp[cp.newaxis, :, :], axis=2)\n",
    "    node2vec_dist_matrix = cp.linalg.norm(emb1_cp[:, cp.newaxis, :] - emb2_cp[cp.newaxis, :, :], axis=2)\n",
    "    hitting_profile_matrix = cp.abs(profile1_cp[:, cp.newaxis] - profile2_cp[cp.newaxis, :])\n",
    "    \n",
    "    cost_matrix = 0.4 * spatial_dist_matrix + 0.3 * node2vec_dist_matrix + 0.3 * hitting_profile_matrix\n",
    "    \n",
    "    # Transferir la matriz de coste a CPU para el algoritmo húngaro\n",
    "    cost_matrix_cpu = cp.asnumpy(cost_matrix)\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix_cpu)\n",
    "    matching = np.zeros((n1, n2), dtype=int)\n",
    "    matching[row_ind, col_ind] = 1\n",
    "    return matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36a5312-3f70-4aa6-8a97-31cf77e1782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_matching_precision(kpts, matching):\n",
    "    \"\"\"\n",
    "    Asume que la correspondencia ideal es la diagonal de la matriz de matching.\n",
    "    \"\"\"\n",
    "    N = kpts.shape[1]\n",
    "    row_ind, col_ind = np.where(matching == 1)\n",
    "    correct = np.sum(row_ind == col_ind)\n",
    "    return correct / N if N != 0 else 0\n",
    "\n",
    "def compute_precision_for_all_categories(dlf, use_cuda=False):\n",
    "    \"\"\"\n",
    "    Para cada categoría:\n",
    "    1. Selecciona aleatoriamente un par de imágenes para visualizar el matching.\n",
    "    2. Recorre todos los pares de imágenes (paralelizado) para calcular la precisión.\n",
    "    3. Guarda los resultados globales en un CSV.\n",
    "    \"\"\"\n",
    "    overall_results = []\n",
    "    \n",
    "    for cat_name, cat_df in dlf.items():\n",
    "        if cat_name == '__pycache___df':\n",
    "            continue\n",
    "        \n",
    "        # Visualización de un par aleatorio\n",
    "        sample = cat_df.sample(2)\n",
    "        row1 = sample.iloc[0]\n",
    "        row2 = sample.iloc[1]\n",
    "        \n",
    "        img1, img2, kpts1, kpts2 = load_and_preprocess_images(row1, row2)\n",
    "        adj1 = delaunay_triangulation(kpts1)\n",
    "        adj2 = delaunay_triangulation(kpts2)\n",
    "        \n",
    "        if use_cuda and HAS_CUPY:\n",
    "            matching = enhanced_spatial_matching_cuda(kpts1, kpts2, adj1, adj2)\n",
    "        else:\n",
    "            matching = enhanced_spatial_matching(kpts1, kpts2, adj1, adj2)\n",
    "        \n",
    "        logger.info(f\"Visualizando par aleatorio para {cat_name}\")\n",
    "        visualize_combined(img1, img2, kpts1, kpts2, adj1, adj2, matching)\n",
    "        \n",
    "        # Paralelizar el cálculo de precisión para cada par de imágenes\n",
    "        precisions = []\n",
    "        n = len(cat_df)\n",
    "        pairs = [(i, j) for i in range(n - 1) for j in range(i + 1, n)]\n",
    "        \n",
    "        def process_pair(pair):\n",
    "            i, j = pair\n",
    "            row_a = cat_df.iloc[i]\n",
    "            row_b = cat_df.iloc[j]\n",
    "            kpts_a, kpts_b = load_keypoints_from_row(row_a, row_b)\n",
    "            A_a = delaunay_triangulation(kpts_a)\n",
    "            A_b = delaunay_triangulation(kpts_b)\n",
    "            if use_cuda and HAS_CUPY:\n",
    "                matching_pair = enhanced_spatial_matching_cuda(kpts_a, kpts_b, A_a, A_b)\n",
    "            else:\n",
    "                matching_pair = enhanced_spatial_matching(kpts_a, kpts_b, A_a, A_b)\n",
    "            return evaluate_matching_precision(kpts_a, matching_pair)\n",
    "        \n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            results = list(executor.map(process_pair, pairs))\n",
    "        \n",
    "        precisions.extend(results)\n",
    "        \n",
    "        media = np.mean(precisions)\n",
    "        std = np.std(precisions)\n",
    "        \n",
    "        logger.info(f\"Categoría {cat_name.capitalize()}: Precisión media = {media:.4f}, Desviación = {std:.4f}\")\n",
    "        logger.info(f\"Resultados procesados para {cat_name} con {len(cat_df)} imágenes\")\n",
    "        \n",
    "        overall_results.append({\n",
    "            \"Category\": cat_name,\n",
    "            \"Mean_Accuracy\": round(media, 4),\n",
    "            \"Std_Deviation\": round(std, 4),\n",
    "            \"Number_of_Images\": len(cat_df)\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(overall_results)\n",
    "    results_df.to_csv(\"results2.csv\", index=False)\n",
    "    logger.info(\"Resultados globales guardados en results2.csv\")\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d414b05-5aa3-4fa5-a826-3edb59e6d0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando CUDA: False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get local object 'compute_hitting_time_matrix_parallel.<locals>.compute_pair'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\jordi\\anaconda3\\Lib\\multiprocessing\\queues.py\", line 264, in _feed\n    obj = _ForkingPickler.dumps(obj)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jordi\\anaconda3\\Lib\\multiprocessing\\reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nAttributeError: Can't get local object 'compute_hitting_time_matrix_parallel.<locals>.compute_pair'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Puedes definir si deseas usar CUDA estableciendo use_cuda=True (si cupy está instalado y hay GPU disponible)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsando CUDA:\u001b[39m\u001b[38;5;124m\"\u001b[39m, HAS_CUPY)\n\u001b[1;32m----> 4\u001b[0m     final_results \u001b[38;5;241m=\u001b[39m compute_precision_for_all_categories(dlf, use_cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Mostrar resultados finales\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     resultados \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mcompute_precision_for_all_categories\u001b[1;34m(dlf, use_cuda)\u001b[0m\n\u001b[0;32m     33\u001b[0m     matching \u001b[38;5;241m=\u001b[39m enhanced_spatial_matching_cuda(kpts1, kpts2, adj1, adj2)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     matching \u001b[38;5;241m=\u001b[39m enhanced_spatial_matching(kpts1, kpts2, adj1, adj2)\n\u001b[0;32m     37\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizando par aleatorio para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m visualize_combined(img1, img2, kpts1, kpts2, adj1, adj2, matching)\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36menhanced_spatial_matching\u001b[1;34m(kpts1, kpts2, adj_matrix1, adj_matrix2)\u001b[0m\n\u001b[0;32m     14\u001b[0m node2vec_emb2 \u001b[38;5;241m=\u001b[39m compute_node2vec_embeddings(G2)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Usar la versión paralela para hitting times (CPU)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m hitting_times1 \u001b[38;5;241m=\u001b[39m compute_hitting_time_matrix_parallel(G1)\n\u001b[0;32m     18\u001b[0m hitting_times2 \u001b[38;5;241m=\u001b[39m compute_hitting_time_matrix_parallel(G2)\n\u001b[0;32m     20\u001b[0m profile1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(hitting_times1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (n1,)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m, in \u001b[0;36mcompute_hitting_time_matrix_parallel\u001b[1;34m(G)\u001b[0m\n\u001b[0;32m     44\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(compute_pair, i, j): (i, j) \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m pairs}\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[1;32m---> 46\u001b[0m     i, j, h_time \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m     47\u001b[0m     hitting_times[i, j] \u001b[38;5;241m=\u001b[39m h_time\n\u001b[0;32m     48\u001b[0m     hitting_times[j, i] \u001b[38;5;241m=\u001b[39m h_time\n",
      "File \u001b[1;32mc:\\Users\\jordi\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\jordi\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jordi\\anaconda3\\Lib\\multiprocessing\\queues.py:264\u001b[0m, in \u001b[0;36mQueue._feed\u001b[1;34m(buffer, notempty, send_bytes, writelock, reader_close, writer_close, ignore_epipe, onerror, queue_sem)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# serialize the data before acquiring the lock\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m obj \u001b[38;5;241m=\u001b[39m _ForkingPickler\u001b[38;5;241m.\u001b[39mdumps(obj)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wacquire \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     send_bytes(obj)\n",
      "File \u001b[1;32mc:\\Users\\jordi\\anaconda3\\Lib\\multiprocessing\\reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[1;34m(cls, obj, protocol)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mcls\u001b[39m(buf, protocol)\u001b[38;5;241m.\u001b[39mdump(obj)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get local object 'compute_hitting_time_matrix_parallel.<locals>.compute_pair'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Puedes definir si deseas usar CUDA estableciendo use_cuda=True (si cupy está instalado y hay GPU disponible)\n",
    "    print(\"Usando CUDA:\", HAS_CUPY)\n",
    "    final_results = compute_precision_for_all_categories(dlf, use_cuda=True)\n",
    "    \n",
    "    # Mostrar resultados finales\n",
    "    resultados = pd.read_csv(\"results2.csv\")\n",
    "    print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f647ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
